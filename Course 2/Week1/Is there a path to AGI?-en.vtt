WEBVTT

1
00:00:01.010 --> 00:00:03.440
Ever since I was a teenager

2
00:00:03.440 --> 00:00:05.715
starting to play around
with neural networks,

3
00:00:05.715 --> 00:00:07.320
I just felt that
the dream of maybe

4
00:00:07.320 --> 00:00:09.630
someday building an AI system

5
00:00:09.630 --> 00:00:11.730
that's as intelligent as myself

6
00:00:11.730 --> 00:00:14.390
or as intelligent
as a typical human,

7
00:00:14.390 --> 00:00:17.475
that that was one of the
most inspiring dreams of AI.

8
00:00:17.475 --> 00:00:19.840
I still hold that
dream alive today.

9
00:00:19.840 --> 00:00:21.600
But I think that the
path to get there is

10
00:00:21.600 --> 00:00:23.970
not clear and could
be very difficult.

11
00:00:23.970 --> 00:00:26.400
I don't know whether
it would take us mere

12
00:00:26.400 --> 00:00:27.780
decades and whether we'll

13
00:00:27.780 --> 00:00:29.745
see breakthroughs
within our lifetimes,

14
00:00:29.745 --> 00:00:33.985
or if it may take centuries
or even longer to get there.

15
00:00:33.985 --> 00:00:37.085
Let's take a look
at what this AGI,

16
00:00:37.085 --> 00:00:39.800
artificial general
intelligence dream is

17
00:00:39.800 --> 00:00:41.210
like and speculate a

18
00:00:41.210 --> 00:00:43.235
bit on what might
be possible paths,

19
00:00:43.235 --> 00:00:46.610
unclear paths, difficult
paths to get there someday.

20
00:00:46.610 --> 00:00:49.820
I think there's been a
lot of unnecessary hype

21
00:00:49.820 --> 00:00:53.815
about AGI or artificial
general intelligence.

22
00:00:53.815 --> 00:00:57.005
Maybe one reason for that is AI

23
00:00:57.005 --> 00:01:00.650
actually includes two
very different things.

24
00:01:00.650 --> 00:01:03.170
One is ANI which

25
00:01:03.170 --> 00:01:05.830
stands for artificial
narrow intelligence.

26
00:01:05.830 --> 00:01:08.435
This is an AI system
that does one thing,

27
00:01:08.435 --> 00:01:10.490
a narrow task, sometimes

28
00:01:10.490 --> 00:01:13.235
really well and can be
incredibly valuable,

29
00:01:13.235 --> 00:01:14.750
such as the smart speaker or

30
00:01:14.750 --> 00:01:16.310
self-driving car or web search,

31
00:01:16.310 --> 00:01:17.600
or AI applied to

32
00:01:17.600 --> 00:01:21.665
specific applications such
as farming or factories.

33
00:01:21.665 --> 00:01:24.435
Over the last several years,

34
00:01:24.435 --> 00:01:28.190
ANI has made tremendous
progress and it's creating,

35
00:01:28.190 --> 00:01:30.845
as you know, tremendous
value in the world today.

36
00:01:30.845 --> 00:01:34.265
Because ANI is a subset of AI,

37
00:01:34.265 --> 00:01:38.525
the rapid progress in ANI
makes it logically true that

38
00:01:38.525 --> 00:01:43.315
AI has also made tremendous
progress in the last decade.

39
00:01:43.315 --> 00:01:45.515
There's a different idea in AI,

40
00:01:45.515 --> 00:01:48.995
which is AGI, artificial
general intelligence.

41
00:01:48.995 --> 00:01:51.290
There's hope of
building AI systems

42
00:01:51.290 --> 00:01:54.655
that could do anything
a typical human can do.

43
00:01:54.655 --> 00:01:57.045
Despite all the progress in

44
00:01:57.045 --> 00:02:00.815
ANI and therefore
tremendous progress in AI,

45
00:02:00.815 --> 00:02:03.470
I'm not sure how much
progress, if any,

46
00:02:03.470 --> 00:02:06.650
we're really making toward AGI.

47
00:02:06.650 --> 00:02:10.100
I think all the progress
in ANI has made people

48
00:02:10.100 --> 00:02:12.140
conclude correctly that there's

49
00:02:12.140 --> 00:02:14.210
tremendous progress in AI.

50
00:02:14.210 --> 00:02:17.390
But that has caused some
people to conclude,

51
00:02:17.390 --> 00:02:20.690
I think incorrectly that
a lot of progress in AI

52
00:02:20.690 --> 00:02:22.250
necessarily means
that there's a lot

53
00:02:22.250 --> 00:02:25.000
of progress towards AGI.

54
00:02:25.000 --> 00:02:29.945
If you have else
about AI and AGI,

55
00:02:29.945 --> 00:02:31.970
sometimes you might find drawing

56
00:02:31.970 --> 00:02:34.610
this picture useful
for explaining some of

57
00:02:34.610 --> 00:02:37.880
the things going on in AI as
well and some of the sources

58
00:02:37.880 --> 00:02:41.925
of unnecessary hype about AGI.

59
00:02:41.925 --> 00:02:45.230
With the rise of
modern deep learning,

60
00:02:45.230 --> 00:02:48.380
we started to simulate
neurons and with

61
00:02:48.380 --> 00:02:50.555
faster and faster computers and

62
00:02:50.555 --> 00:02:54.340
even GPUs we can simulate
even more neurons.

63
00:02:54.340 --> 00:02:56.280
I think there was this big hope

64
00:02:56.280 --> 00:02:58.230
many years ago that, boy,

65
00:02:58.230 --> 00:03:01.695
if only we could simulate a
lot of neurons then we can

66
00:03:01.695 --> 00:03:03.650
simulate the human
brain or something like

67
00:03:03.650 --> 00:03:06.350
a human brain and we've
really intelligent systems.

68
00:03:06.350 --> 00:03:08.270
Sadly, it's turned out not to

69
00:03:08.270 --> 00:03:10.975
be quite as simple as that.

70
00:03:10.975 --> 00:03:16.190
I think two reasons
for this is first,

71
00:03:16.190 --> 00:03:17.645
if you look at the

72
00:03:17.645 --> 00:03:19.880
artificial neural
networks we're building,

73
00:03:19.880 --> 00:03:22.175
they are so simple that

74
00:03:22.175 --> 00:03:25.340
a logistic regression unit
is really nothing like what

75
00:03:25.340 --> 00:03:27.830
any biological neuron
is doing is so much

76
00:03:27.830 --> 00:03:29.720
simpler than what any neuron

77
00:03:29.720 --> 00:03:31.700
in your brain or mine is doing.

78
00:03:31.700 --> 00:03:34.400
Second, even to this day,

79
00:03:34.400 --> 00:03:37.620
I think we have almost no
idea how the brain works.

80
00:03:37.620 --> 00:03:39.200
There are still
fundamental questions

81
00:03:39.200 --> 00:03:40.970
about how exactly does

82
00:03:40.970 --> 00:03:42.965
a neuron map from inputs to

83
00:03:42.965 --> 00:03:45.505
outputs that we just
don't know today.

84
00:03:45.505 --> 00:03:48.080
Trying to simulate
that in a computer,

85
00:03:48.080 --> 00:03:51.980
much less a single logistic
function is just so

86
00:03:51.980 --> 00:03:53.780
far from an accurate model of

87
00:03:53.780 --> 00:03:56.180
what the human brain
actually does.

88
00:03:56.180 --> 00:04:00.260
Given our very limited
understanding both

89
00:04:00.260 --> 00:04:01.820
now and probably for

90
00:04:01.820 --> 00:04:04.690
the near future of how
the human brain works,

91
00:04:04.690 --> 00:04:07.985
I think just trying to
simulate the human brain as

92
00:04:07.985 --> 00:04:12.145
a path to AGI will be an
incredibly difficult path.

93
00:04:12.145 --> 00:04:15.710
Having said that, is there

94
00:04:15.710 --> 00:04:17.210
any hope of within

95
00:04:17.210 --> 00:04:20.149
our lifetimes seeing
breakthroughs in AGI?

96
00:04:20.149 --> 00:04:23.480
Let me share with you
some evidence that

97
00:04:23.480 --> 00:04:27.695
helps me keep that hope
alive, at least for myself.

98
00:04:27.695 --> 00:04:31.265
There have been some
fascinating experiments done on

99
00:04:31.265 --> 00:04:34.490
animals that shows or strongly

100
00:04:34.490 --> 00:04:37.565
suggests that the same piece of

101
00:04:37.565 --> 00:04:40.280
biological brain tissue can do

102
00:04:40.280 --> 00:04:42.965
a surprisingly wide
range of tasks.

103
00:04:42.965 --> 00:04:45.425
This has led to the one learning

104
00:04:45.425 --> 00:04:47.810
algorithm hypothesis
that maybe a lot

105
00:04:47.810 --> 00:04:49.985
of intelligence could be due to

106
00:04:49.985 --> 00:04:52.650
one or a small handful
of learning algorithms.

107
00:04:52.650 --> 00:04:54.140
If only we could figure out what

108
00:04:54.140 --> 00:04:56.855
that one or small handful
of algorithms are,

109
00:04:56.855 --> 00:05:00.740
we may be able to implement
that in a computer someday.

110
00:05:00.740 --> 00:05:04.445
Let me share with you some
details of those experiments.

111
00:05:04.445 --> 00:05:07.055
This is a result
due to Roe et al.

112
00:05:07.055 --> 00:05:09.440
from many decades ago.

113
00:05:09.440 --> 00:05:11.750
The part of your brain shown

114
00:05:11.750 --> 00:05:14.330
here is your auditory cortex,

115
00:05:14.330 --> 00:05:16.940
and your brain is wired to feed

116
00:05:16.940 --> 00:05:18.770
signals from your ears

117
00:05:18.770 --> 00:05:20.870
in the form of
electrical impulses,

118
00:05:20.870 --> 00:05:23.000
depending on what
sound your ear is

119
00:05:23.000 --> 00:05:26.060
detecting to that
auditory cortex.

120
00:05:26.060 --> 00:05:29.600
It turns out that if
you were to rewire

121
00:05:29.600 --> 00:05:31.970
an animal brain,s to cut

122
00:05:31.970 --> 00:05:35.120
the wire between the ear
and the auditory cortex,

123
00:05:35.120 --> 00:05:38.750
and instead feed in images
to the auditory cortex,

124
00:05:38.750 --> 00:05:41.570
then the auditory
cortex learns to see.

125
00:05:41.570 --> 00:05:43.595
Auditory refers to sound,

126
00:05:43.595 --> 00:05:45.320
and so this piece of the brain

127
00:05:45.320 --> 00:05:47.600
that in most people
learns to here,

128
00:05:47.600 --> 00:05:49.580
when it is fed different data,

129
00:05:49.580 --> 00:05:52.025
it instead learns to see.

130
00:05:52.025 --> 00:05:53.945
Here's another example.

131
00:05:53.945 --> 00:05:57.500
This part of your brain is
your somatosensory cortex,

132
00:05:57.500 --> 00:06:00.710
somatosensory refers
to touch processing.

133
00:06:00.710 --> 00:06:02.990
If you were to similarly rewire

134
00:06:02.990 --> 00:06:05.960
the brain to cut
the connection from

135
00:06:05.960 --> 00:06:08.270
the touch sensors to that
part of the brain and instead

136
00:06:08.270 --> 00:06:11.045
rewire the brain
to feed in images,

137
00:06:11.045 --> 00:06:14.475
then the somatosensory
cortex learns to see.

138
00:06:14.475 --> 00:06:17.080
There's been a sequence
of experiments like this,

139
00:06:17.080 --> 00:06:19.795
showing that many different
parts of the brain,

140
00:06:19.795 --> 00:06:24.010
just depending on what data
is given can learn to see,

141
00:06:24.010 --> 00:06:25.300
or learn to feel,

142
00:06:25.300 --> 00:06:28.210
or learn to hear as if there was

143
00:06:28.210 --> 00:06:30.310
maybe one algorithm that

144
00:06:30.310 --> 00:06:32.485
just depending on what
data or this given,

145
00:06:32.485 --> 00:06:35.940
learns to process that
inputs accordingly.

146
00:06:35.940 --> 00:06:38.495
There happens systems built

147
00:06:38.495 --> 00:06:41.450
which take a camera
may be mounted to

148
00:06:41.450 --> 00:06:44.285
someone's forehead and
maps it to a pattern

149
00:06:44.285 --> 00:06:47.975
of voltages in a grid
on someone's tongue.

150
00:06:47.975 --> 00:06:50.720
By mapping a grayscale image

151
00:06:50.720 --> 00:06:53.390
to a pattern of voltages
on your tongue,

152
00:06:53.390 --> 00:06:56.510
this can help people
that are not cited

153
00:06:56.510 --> 00:07:00.710
line individuals learn
to see with your tongue,

154
00:07:00.710 --> 00:07:03.620
or they've been fascinating
experiments with

155
00:07:03.620 --> 00:07:06.545
human echolocation
or humans sonar,

156
00:07:06.545 --> 00:07:10.835
so animals like dolphins
and bats use sonar to see,

157
00:07:10.835 --> 00:07:13.370
and researchers have found

158
00:07:13.370 --> 00:07:17.640
that if you train humans
to make clicking sounds,

159
00:07:17.710 --> 00:07:22.100
and listen to how that
bounces off surroundings,

160
00:07:22.100 --> 00:07:24.350
humans can sometimes learn

161
00:07:24.350 --> 00:07:27.660
some degree of
human echolocation.

162
00:07:27.660 --> 00:07:30.970
Or this is a haptic belt,

163
00:07:30.970 --> 00:07:33.550
and my research lab
at Stanford once

164
00:07:33.550 --> 00:07:36.480
built something like
this before as well,

165
00:07:36.480 --> 00:07:40.310
but if you mount a ring of
buzzes around your waist

166
00:07:40.310 --> 00:07:44.585
and program it using a
magnetic compass, so that say,

167
00:07:44.585 --> 00:07:47.300
the buzzers to the
North most direction

168
00:07:47.300 --> 00:07:49.380
are always vibrating slowly,

169
00:07:49.380 --> 00:07:52.075
then you somehow gain
a direction sense,

170
00:07:52.075 --> 00:07:54.280
which some animals
have, but humans don't.

171
00:07:54.280 --> 00:07:56.020
Then it just feels like you're

172
00:07:56.020 --> 00:07:58.435
walking around and you
just know where North is,

173
00:07:58.435 --> 00:08:01.420
it doesn't feel like that
part of my waist is buzzing,

174
00:08:01.420 --> 00:08:04.035
it feels like, oh, I know
where that north is.

175
00:08:04.035 --> 00:08:07.745
Or surgeries implant a third eye

176
00:08:07.745 --> 00:08:09.530
onto frog and the brain

177
00:08:09.530 --> 00:08:11.945
just learns with you
with this input.

178
00:08:11.945 --> 00:08:13.580
There have been a variety of

179
00:08:13.580 --> 00:08:15.170
experiments like
these just showing

180
00:08:15.170 --> 00:08:18.440
that the human brain is
amazingly adaptable,

181
00:08:18.440 --> 00:08:21.020
neuroscientists say
is amazingly plastic,

182
00:08:21.020 --> 00:08:23.045
they just mean adaptable to

183
00:08:23.045 --> 00:08:26.495
bewildering range
of sensor inputs,

184
00:08:26.495 --> 00:08:28.025
and so the question is,

185
00:08:28.025 --> 00:08:31.370
if the same piece of brain
tissue can learn to see,

186
00:08:31.370 --> 00:08:33.320
or touch, or feel,

187
00:08:33.320 --> 00:08:34.775
or even other things,

188
00:08:34.775 --> 00:08:36.620
what is the average of users,

189
00:08:36.620 --> 00:08:38.495
and can we replicate
this algorithm

190
00:08:38.495 --> 00:08:40.640
and implemented in a computer?

191
00:08:40.640 --> 00:08:43.160
I do feel bad for the
frog and other animals,

192
00:08:43.160 --> 00:08:45.305
or which these
experiments were done,

193
00:08:45.305 --> 00:08:47.480
although I think the conclusions

194
00:08:47.480 --> 00:08:49.834
are also quite fascinating.

195
00:08:49.834 --> 00:08:54.200
Even to this day, I think
working on AGI is one of

196
00:08:54.200 --> 00:08:56.330
the most fascinating science

197
00:08:56.330 --> 00:08:58.370
and engineering
problems of all time,

198
00:08:58.370 --> 00:09:02.510
and maybe you will choose
someday to do research on it.

199
00:09:02.510 --> 00:09:06.620
However, I think it's important
to avoid over-hyping,

200
00:09:06.620 --> 00:09:09.245
I don't know if the
brain is really

201
00:09:09.245 --> 00:09:11.660
one or a small handful
of algorithms,

202
00:09:11.660 --> 00:09:13.100
and even if it were,

203
00:09:13.100 --> 00:09:14.360
I have no idea,

204
00:09:14.360 --> 00:09:17.435
and I don't think anyone
knows what the algorithm is,

205
00:09:17.435 --> 00:09:20.015
but I still this hope alive,

206
00:09:20.015 --> 00:09:21.335
and maybe it is,

207
00:09:21.335 --> 00:09:22.820
and maybe we could,

208
00:09:22.820 --> 00:09:24.620
through a lot of hard work,

209
00:09:24.620 --> 00:09:27.605
someday discover an
approximation to it.

210
00:09:27.605 --> 00:09:32.225
I still find this one of the
most fascinating topics,

211
00:09:32.225 --> 00:09:34.040
I really think about it in

212
00:09:34.040 --> 00:09:36.620
my spare time and maybe someday,

213
00:09:36.620 --> 00:09:40.920
you be the one to make a
contribution to this problem.

214
00:09:40.930 --> 00:09:46.280
In the short term, I think
even without pursuing AGI,

215
00:09:46.280 --> 00:09:48.575
machine learning
and neural networks

216
00:09:48.575 --> 00:09:50.525
are very powerful tool,

217
00:09:50.525 --> 00:09:52.970
and even without
trying to go all

218
00:09:52.970 --> 00:09:55.520
the way to build
human-level intelligence,

219
00:09:55.520 --> 00:09:56.810
I think you find

220
00:09:56.810 --> 00:09:59.510
neural networks to be
an incredibly powerful,

221
00:09:59.510 --> 00:10:01.355
and useful set of tools

222
00:10:01.355 --> 00:10:04.415
for applications that
you might build.

223
00:10:04.415 --> 00:10:08.135
That's it for the required
videos of this week,

224
00:10:08.135 --> 00:10:11.450
congratulations on getting to
this point in the lessons.

225
00:10:11.450 --> 00:10:13.550
After this, we'll also have

226
00:10:13.550 --> 00:10:16.010
a few optional videos
to dive a little bit

227
00:10:16.010 --> 00:10:17.840
more deeply into

228
00:10:17.840 --> 00:10:20.715
efficient implementations
of neural networks.

229
00:10:20.715 --> 00:10:24.095
In particular, in the
optional videos to come,

230
00:10:24.095 --> 00:10:26.510
I'd like to share with
you some details of how

231
00:10:26.510 --> 00:10:30.405
to vectorize implementations
of neural networks.

232
00:10:30.405 --> 00:10:34.620
I hope you also take a
look at those videos.